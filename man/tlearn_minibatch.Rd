% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tlearn_minibatch.R
\name{tlearn_minibatch}
\alias{tlearn_minibatch}
\title{Transfer learn in minibatches}
\usage{
tlearn_minibatch(A, w, chunk_size = 1000, verbose = TRUE, ...)
}
\arguments{
\item{A}{samples to project: matrix of features x samples, dense or sparse}

\item{w}{feature coefficients model: matrix of features x factors}

\item{chunk_size}{number of samples to project at a time}

\item{verbose}{show progress bar}

\item{...}{additional arguments to tlearn (use regularizations with caution)}
}
\value{
h, a sample embeddings matrix of dimensions "factors x samples".
}
\description{
Given a very large sparse matrix of samples, minibatch tlearn reduces memory overhead by splitting the sample matrix into chunks and projecting one chunk at a time.
}
\details{
You can achieve the same result by manually chunking the data and running tlearn on each chunk, then binding the chunks together again. Of course, model-wide regularization should be used with caution.

Should you chunk?
* Pros: You get a progress bar, reduced memory overhead, and still just a single matrix as a result
* Cons: Takes fractions of a second longer, no support for weights, warm-start initialization, or model-wide regularization.
}
\seealso{
\code{\link{tlearn}}
}
